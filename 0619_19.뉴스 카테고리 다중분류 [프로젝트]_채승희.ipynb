{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9caac31",
   "metadata": {},
   "source": [
    "### ✏️ 단어장 개수별 ML 모델 성능 비교표\n",
    "| Vocabulary Size | Model               | Accuracy | F1-Score |\n",
    "|------------------|--------------------|----------|----------|\n",
    "| 5000             | ComplementNB       |  0.7707  |  0.7459  |\n",
    "|                  | LogisticRegression |  0.8059  |  0.8000  |\n",
    "|                  | LinearSVC          |  0.7654  |  0.7614  |\n",
    "|                  | <span style=\"color:red\">DecisionTree</span>       |  <span style=\"color:red\">0.6180</span>  |  <span style=\"color:red\">0.5730</span>  |\n",
    "|                  | RandomForest       |  0.6999  |  0.6757  |\n",
    "|                  | GradientBoosting   |  0.7658  |  0.7640  |\n",
    "|                  | XGBoost            |  0.7961  |  0.7897  |\n",
    "|                  | <span style=\"color:blue\">Soft Voting</span>        |  <span style=\"color:blue\">0.8157</span>  |  <span style=\"color:blue\">0.8124</span> |\n",
    "| 10000            | ComplementNB       |  0.7707  |  0.7457  |\n",
    "|                  | LogisticRegression |  0.8085  |  0.8023  |\n",
    "|                  | LinearSVC          |  0.7850  |  0.7811  |\n",
    "|                  | <span style=\"color:red\">DecisionTree</span>       |  <span style=\"color:red\">0.6202</span>  |  <span style=\"color:red\">0.5776</span>  |\n",
    "|                  | RandomForest       |  0.6741  |  0.6429  |\n",
    "|                  | GradientBoosting   |  0.7671  |  0.7631  |\n",
    "|                  | XGBoost            |  0.7930  |  0.7856  |\n",
    "|                  | <span style=\"color:blue\">Soft Voting</span>        |  <span style=\"color:blue\">0.8143</span>  |  <span style=\"color:blue\">0.8111</span> |\n",
    "| NaN (All words)  | ComplementNB       |  0.7649  |  0.7347  |\n",
    "|                  | LogisticRegression |  0.8112  |  0.8055  |\n",
    "|                  | LinearSVC          |  0.7876  |  0.7842  |\n",
    "|                  | <span style=\"color:red\">DecisionTree</span>       |  <span style=\"color:red\">0.6211</span>  | <span style=\"color:red\">0.5769</span> |\n",
    "|                  | RandomForest       |  0.6544  |  0.6225  |\n",
    "|                  | GradientBoosting   |  0.7680  |  0.7627  |\n",
    "|                  | XGBoost            |  0.7938  |  0.7876  |\n",
    "|                  | <span style=\"color:blue\">Soft Voting</span>        | <span style=\"color:blue\">0.8161</span> | <span style=\"color:blue\">0.8114</span> |\n",
    "\n",
    "### ✏️ 워드 임베딩 -> ML/DL 모델 성능 비교표\n",
    "| Vectorization | Model                  | Accuracy | F1-Score |\n",
    "|---------------|------------------------|----------|----------|\n",
    "| Word2Vec      | ML_XGBoost             |  0.7222  |  0.7030  |\n",
    "|               | ML_Logistic Regression |  0.7262  |  0.7246  |\n",
    "|               | <span style=\"color:red\">DL_Dense NN</span>    |  <span style=\"color:red\">0.6817</span>  |  <span style=\"color:red\">0.6526</span>  |\n",
    "|               | DL_RNN                 |  0.7636  |  0.7476  |\n",
    "|               | <span style=\"color:blue\">DL_CNN + BiLSTM</span> |  <span style=\"color:blue\">0.7667</span>  |  <span style=\"color:blue\">0.7509</span>  | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcca1b3",
   "metadata": {},
   "source": [
    "### 회고\n",
    "**[오늘 진행한 작업]**\n",
    "1. num_words 5000과 10000을 테스트하여 성능 비교 표를 만들었다.\n",
    "    - inf에 대한 결과는 팀원에게 제공받았다.\n",
    "2. nltk의 word_tokenize로 토큰화 테스트 -> split과의 차이가 크게 존재하지 않는 것 같다. (코랩 가이드 결과와 비교했을 때)\n",
    "3. 워드 임베딩한 후, 머신러닝과 딥러닝 모델 비교 테스트\n",
    "    - epochs을 늘리고 싶은데, 그냥 50을 돌려버리니 과적합이 발생하는 것 같았다.  \n",
    "    -> 그래서 early stopping 콜백을 추가한 후 모델 학습\n",
    "    - Dense NN과 RNN의 단방향 LSTM 테스트 후 성능 점수가 좋지 않아 새로운 모델 조합 시도  \n",
    "    -> CNN + 양방향 LSTM...성능이 아주 조금 향상되었다.\n",
    "\n",
    "**[느낀 점]**\n",
    "1. 딥러닝이면 당연히 머신러닝보다 성능이 좋을 것 같았는데 그렇지 않다.\n",
    "    - 딥러닝은 활용하는 모델, 레이어, 유닛 수 등 정말 다양하게 테스트 해봐야 최상의 결과를 만들어내는 모델을 찾을 수 있지 않을까?\n",
    "2. 딥러닝이 머신러닝보다 속도가 오래 걸릴 줄 알았는데, 이것 또한 그렇지 않았다.\n",
    "    - 머신러닝의 GradientBoosting, Voting 앙상블 모델이 early stopping을 적용한 딥러닝 모델 학습보다도 오래 걸린 것 같다.\n",
    "    - 특히 Logistic Regression에 워드임베딩한 데이터를 학습시킬 때가 가장 오래 걸렸다.\n",
    "    - 전반적으로 머신러닝에 어거지(?)로 워드임베딩한 데이터를 학습시키니 시간이 다들 오래 걸려서 TF-IDF와 Word2Vec의 비교는 이번에 진행하지 못했다.\n",
    "3. 단어장 개수에 따른 모델 성능에 크게 차이가 없다.\n",
    "    - 단어장 개수를 제한하지 않으면 당연히 성능이 훨씬 좋을 줄 알았다.  \n",
    "    -> inf일 때가 가장 좋긴 하지만, 오히려 5000개일 때와 0.0004로 크게 차이가 없었다.\n",
    "    - 단어장 개수를 제한할 때, 빈도 수가 상위인 순서로 사용하기 때문에 그런걸까 했다.\n",
    "    - inf 실험은 팀원분이 진행해주어 현재 명확한 비교는 어렵지만 학습 속도에 따라서 단어장을 몇개로 제한할지 결정할 필요가 있을 것 같다.\n",
    "\n",
    "**[아쉬운 점]**\n",
    "1. 여러 비교를 해보고 싶은데 시간상의 어려움\n",
    "    - nltk의 word_tokenize와 단순 split을 사용할 때의 성능 비교\n",
    "    - 문장 최대 길이도 100에서 200으로 변경해서 성능 비교 등\n",
    "    - 다양한 성능 비교를 진행해보고 싶은데, 모든 모델을 반복해서 돌려야하기 때문에 시간상의 어려움\n",
    "2. 여러 방식을 비교할 때, 노트북 코드를 어떻게 깔끔하게 정리할 수 있을까?\n",
    "    - 시간상의 어려움도 있지만, 노트북에서 코드와 변수명, 결과 시각화(표나 그래프)를  \n",
    "    어떤 순서와 방식으로 정리하면 깔끔하게 비교할 수 있을지 아직 너무 어렵다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98adfa7d",
   "metadata": {},
   "source": [
    "# 1. 단어장 개수별 ML 모델 성능 비교\n",
    "- 벡터화는 TF-IDF로 통일\n",
    "- 성능 지표는 Accuracy / F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e4b95",
   "metadata": {},
   "source": [
    "# 1.1 num_words = 10,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f3b6c",
   "metadata": {},
   "source": [
    "### 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da37c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185e5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터로 나누어 변수에 각각 저장\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1825086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 뉴스 데이터로 복원\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5950e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수로부터 단어를 얻을 수 있는 index_word가 필요\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b4fe732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "# 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9156ee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded_test = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded_test.append(t)\n",
    "\n",
    "x_test = decoded_test\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d737c9",
   "metadata": {},
   "source": [
    "### 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0862b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화 DTM, TF-idf 방법\n",
    "dtmvector = CountVectorizer()\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "x_test_dtm= dtmvector.transform(x_test)\n",
    "\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "x_test_tfidf = tfidf_transformer.transform(x_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f45b845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<sos> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely <unk> borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in <unk> financial eligibility standards indicated as many as one half of <unk> borrowers who received new loans from the agency in 1986 would be <unk> under the proposed system the agency has proposed evaluating <unk> credit using a variety of financial ratios instead of relying solely on <unk> ability senate agriculture committee chairman patrick leahy d vt <unk> the proposed eligibility changes telling <unk> administrator <unk> clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to <unk> its 70 billion dlr loan portfolio in a <unk> yet <unk> manner crowley of gao <unk> <unk> arm said the proposed credit <unk> system attempted to ensure that <unk> would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892ba4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/chaeseunghee/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "# 벡터화 W2V방법\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize  # word_tokenize 대신 doc.split()도 가능\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 우선 문장을 토큰화 시킵시다. nltk tokenize 사용! -> 위에서 DTM만들때는 왜 안해줬냐! -> CountVectorizer에서 띄어쓰기 기반 토큰화가 내장되있음\n",
    "# x_train_tokenized = [sentence.split() for sentence in x_train]\n",
    "# x_test_tokenized = [sentence.split() for sentence in x_test]\n",
    "\n",
    "x_train_tokenized = [word_tokenize(sentence) for sentence in x_train]\n",
    "x_test_tokenized = [word_tokenize(sentence) for sentence in x_test]\n",
    "\n",
    "# vector사이즈를 늘리거나 줄여보세요 아마 512 가장많이쓰이는 방식\n",
    "model = Word2Vec(sentences = x_train_tokenized, vector_size = 256, window = 5, min_count = 5, workers = 4, sg = 0)\n",
    "print(\"모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92596d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('glenn', 0.8334102630615234), ('bow', 0.8264259696006775), ('noranda', 0.8130820393562317), ('amylum', 0.8096473217010498), ('barney', 0.8089924454689026), ('iii', 0.8068000078201294), ('jerry', 0.8062423467636108), ('rica', 0.8049752712249756), ('harris', 0.7969186305999756), ('ontario', 0.790473461151123)]\n"
     ]
    }
   ],
   "source": [
    "# W2V이 잘되었는지 확인\n",
    "model_result = model.wv.most_similar('man')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f4e5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 Word2Vec 모델\n",
    "w2v_model = model\n",
    "\n",
    "# 각 문장을 벡터화 시키는 코드\n",
    "def vectorize_sentence(sentence, model, max_len):\n",
    "    vecs = []\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            vecs.append(model.wv[word])\n",
    "        else:\n",
    "            vecs.append(np.zeros(model.vector_size))\n",
    "    # Padding\n",
    "    if len(vecs) < max_len:\n",
    "        vecs += [np.zeros(model.vector_size)] * (max_len - len(vecs))\n",
    "    else:\n",
    "        vecs = vecs[:max_len]\n",
    "    return np.array(vecs)\n",
    "\n",
    "\n",
    "# 최대 문장길이를 잘 잡아주세요\n",
    "x_train_w2v = np.array([vectorize_sentence(s, w2v_model, max_len=100) for s in x_train_tokenized])\n",
    "x_test_w2v = np.array([vectorize_sentence(s, w2v_model, max_len=100) for s in x_test_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d035a2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 100, 256)\n",
      "(2246, 100, 256)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_w2v.shape)\n",
    "print(x_test_w2v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b531c99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 256)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 단어단위에서 문장단위로 바꿔줘야합니다.. ML은 2차원데이터만 받을수있기때문\n",
    "# 문장에 대해서 토큰들의 벡터를 평균을 취해줍니다.\n",
    "\n",
    "# Word2Vec 임베딩 시퀀스: (8982, 100, 256)\n",
    "x_w2v_seq_train = x_train_w2v\n",
    "x_w2v_seq_test = x_test_w2v\n",
    "# 평균 풀링 → (8982, 256)\n",
    "x_w2v_avg_train = np.mean(x_w2v_seq_train, axis=1)\n",
    "x_w2v_avg_test = np.mean(x_w2v_seq_test, axis=1)\n",
    "print(x_w2v_avg_train.shape)  # (8982, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2702bd6",
   "metadata": {},
   "source": [
    "### 모델 정의 및 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "353c9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25b93b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장 리스트\n",
    "results = []\n",
    "\n",
    "# 모델 학습/예측/평가 함수\n",
    "def evaluate_model(model, model_name, x_train, y_train, x_test, y_test, vector_type=\"TF-IDF\"):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"\\n▶️ [{vector_type}] {model_name}\")\n",
    "    print(f\"✅ Accuracy : {acc:.4f}\")\n",
    "    print(f\"✅ F1-score : {f1:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'Vectorizer': vector_type,\n",
    "        'Model': model_name,\n",
    "        'Accuracy': acc,\n",
    "        'F1-score': f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72976eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델 정의\n",
    "cb = ComplementNB()\n",
    "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000, random_state=0)\n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False, random_state=0)\n",
    "dt = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "rf = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3: 진행 상황 확인 가능\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=5, eval_metric='mlogloss')\n",
    "\n",
    "# Soft voting\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators = [\n",
    "        ('lr', lr),\n",
    "        ('nb', cb),\n",
    "        ('gb', grbt)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd89aaf",
   "metadata": {},
   "source": [
    "#### Complement Naive Bayes Classifier(CNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c52dd86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] ComplementNB\n",
      "✅ Accuracy : 0.7707\n",
      "✅ F1-score : 0.7457\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(cb, \"ComplementNB\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf015d77",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "294d1b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] LogisticRegression\n",
      "✅ Accuracy : 0.8085\n",
      "✅ F1-score : 0.8023\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(lr, \"LogisticRegression\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(lr, \"LogisticRegression\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e9afc",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b94968e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] LinearSVC\n",
      "✅ Accuracy : 0.7850\n",
      "✅ F1-score : 0.7811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaeseunghee/miniconda3/envs/tf_aiffel/lib/python3.10/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(lsvc, \"LinearSVC\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(lsvc, \"LinearSVC\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d13965",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7ecdae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] DecisionTree\n",
      "✅ Accuracy : 0.6202\n",
      "✅ F1-score : 0.5776\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(dt, \"DecisionTree\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(dt, \"DecisionTree\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7fe84",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "596c90c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] RandomForest\n",
      "✅ Accuracy : 0.6741\n",
      "✅ F1-score : 0.6429\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(rf, \"RandomForest\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(rf, \"RandomForest\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032fa0d",
   "metadata": {},
   "source": [
    "#### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d132f386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] GradientBoosting\n",
      "✅ Accuracy : 0.7671\n",
      "✅ F1-score : 0.7637\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(grbt, \"GradientBoosting\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(grbt, \"GradientBoosting\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58236de8",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05263389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] XGBoost\n",
      "✅ Accuracy : 0.7930\n",
      "✅ F1-score : 0.7856\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(xgb, \"XGBoost\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(xgb, \"XGBoost\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7dcfa6",
   "metadata": {},
   "source": [
    "#### Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e855b3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] SoftVoting\n",
      "✅ Accuracy : 0.8143\n",
      "✅ F1-score : 0.8111\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(voting_classifier, \"SoftVoting\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(lsvc, \"LinearSVC\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bc643",
   "metadata": {},
   "source": [
    "#### 모델별 성능 비교표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>SoftVoting</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7707</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.7671</td>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.8143</td>\n",
       "      <td>0.7930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.5776</td>\n",
       "      <td>0.7637</td>\n",
       "      <td>0.7811</td>\n",
       "      <td>0.8023</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.7856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model     ComplementNB  DecisionTree  GradientBoosting  LinearSVC  \\\n",
       "Accuracy        0.7707        0.6202            0.7671     0.7850   \n",
       "F1-score        0.7457        0.5776            0.7637     0.7811   \n",
       "\n",
       "Model     LogisticRegression  RandomForest  SoftVoting  XGBoost  \n",
       "Accuracy              0.8085        0.6741      0.8143   0.7930  \n",
       "F1-score              0.8023        0.6429      0.8111   0.7856  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=['Accuracy'], ascending=[False]).reset_index(drop=True)\n",
    "pivot = results_df.pivot_table(index='Model', values=['Accuracy', 'F1-score']).T\n",
    "display(pivot.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25d26c",
   "metadata": {},
   "source": [
    "## 1.2 num_words = 5,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a5f95",
   "metadata": {},
   "source": [
    "### 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a437eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터로 나누어 변수에 각각 저장\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f89df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a836a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef812c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68752c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded_test = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded_test.append(t)\n",
    "\n",
    "x_test = decoded_test\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36d59c0",
   "metadata": {},
   "source": [
    "### 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6771bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화 DTM, TF-idf 방법\n",
    "dtmvector = CountVectorizer()\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "x_test_dtm= dtmvector.transform(x_test)\n",
    "\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "x_test_tfidf = tfidf_transformer.transform(x_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45b8b33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "x_train_tokenized = [word_tokenize(sentence) for sentence in x_train]\n",
    "x_test_tokenized = [word_tokenize(sentence) for sentence in x_test]\n",
    "\n",
    "# vector사이즈를 늘리거나 줄여보세요 아마 512 가장많이쓰이는 방식\n",
    "model = Word2Vec(sentences = x_train_tokenized, vector_size = 256, window = 5, min_count = 5, workers = 4, sg = 0)\n",
    "print(\"모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92a65846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('frank', 0.8094755411148071), ('lewis', 0.7975389957427979), ('jim', 0.7940674424171448), ('roberts', 0.7862080335617065), ('gordon', 0.7708436846733093), ('speaker', 0.7659049034118652), ('moore', 0.7617512941360474), ('site', 0.760253369808197), ('jr', 0.7539461851119995), ('iii', 0.7532680034637451)]\n"
     ]
    }
   ],
   "source": [
    "# W2V이 잘되었는지 확인\n",
    "model_result = model.wv.most_similar('man')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57057c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 Word2Vec 모델\n",
    "w2v_model = model\n",
    "\n",
    "# 각 문장을 벡터화 시키는 코드\n",
    "def vectorize_sentence(sentence, model, max_len):\n",
    "    vecs = []\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            vecs.append(model.wv[word])\n",
    "        else:\n",
    "            vecs.append(np.zeros(model.vector_size))\n",
    "    # Padding\n",
    "    if len(vecs) < max_len:\n",
    "        vecs += [np.zeros(model.vector_size)] * (max_len - len(vecs))\n",
    "    else:\n",
    "        vecs = vecs[:max_len]\n",
    "    return np.array(vecs)\n",
    "\n",
    "\n",
    "# 최대 문장길이를 잘 잡아주세요\n",
    "x_train_w2v = np.array([vectorize_sentence(s, w2v_model, max_len=100) for s in x_train_tokenized])\n",
    "x_test_w2v = np.array([vectorize_sentence(s, w2v_model, max_len=100) for s in x_test_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10197a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 100, 256)\n",
      "(2246, 100, 256)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_w2v.shape)\n",
    "print(x_test_w2v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be50524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 256)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 단어단위에서 문장단위로 바꿔줘야합니다.. ML은 2차원데이터만 받을수있기때문\n",
    "# 문장에 대해서 토큰들의 벡터를 평균을 취해줍니다.\n",
    "\n",
    "# Word2Vec 임베딩 시퀀스: (8982, 100, 256)\n",
    "x_w2v_seq_train = x_train_w2v\n",
    "x_w2v_seq_test = x_test_w2v\n",
    "# 평균 풀링 → (8982, 256)\n",
    "x_w2v_avg_train = np.mean(x_w2v_seq_train, axis=1)\n",
    "x_w2v_avg_test = np.mean(x_w2v_seq_test, axis=1)\n",
    "print(x_w2v_avg_train.shape)  # (8982, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79a664",
   "metadata": {},
   "source": [
    "### 모델 정의 및 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ef0698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장 리스트\n",
    "results_5000 = []\n",
    "\n",
    "# 모델 학습/예측/평가 함수\n",
    "def evaluate_model(model, model_name, x_train, y_train, x_test, y_test, vector_type=\"TF-IDF\"):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"\\n▶️ [{vector_type}] {model_name}\")\n",
    "    print(f\"✅ Accuracy : {acc:.4f}\")\n",
    "    print(f\"✅ F1-score : {f1:.4f}\")\n",
    "\n",
    "    results_5000.append({\n",
    "        'Vectorizer': vector_type,\n",
    "        'Model': model_name,\n",
    "        'Accuracy': acc,\n",
    "        'F1-score': f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba561c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델 정의\n",
    "cb = ComplementNB()\n",
    "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000, random_state=0)\n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False, random_state=0)\n",
    "dt = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "rf = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3: 진행 상황 확인 가능\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=5, eval_metric='mlogloss')\n",
    "\n",
    "# Soft voting\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators = [\n",
    "        ('lr', lr),\n",
    "        ('nb', cb),\n",
    "        ('gb', grbt)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21252b62",
   "metadata": {},
   "source": [
    "#### ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa644413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] ComplementNB\n",
      "✅ Accuracy : 0.7707\n",
      "✅ F1-score : 0.7459\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(cb, \"ComplementNB\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968a8b1",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bca9add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] LogisticRegression\n",
      "✅ Accuracy : 0.8059\n",
      "✅ F1-score : 0.8000\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(lr, \"LogisticRegression\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(lr, \"LogisticRegression\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50553dc2",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "373d5dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] LinearSVC\n",
      "✅ Accuracy : 0.7654\n",
      "✅ F1-score : 0.7614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaeseunghee/miniconda3/envs/tf_aiffel/lib/python3.10/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(lsvc, \"LinearSVC\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(lsvc, \"LinearSVC\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667e0f2",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dddcabb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] DecisionTree\n",
      "✅ Accuracy : 0.6180\n",
      "✅ F1-score : 0.5730\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(dt, \"DecisionTree\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(dt, \"DecisionTree\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c1e9c8",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "454eee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] RandomForest\n",
      "✅ Accuracy : 0.6999\n",
      "✅ F1-score : 0.6757\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(rf, \"RandomForest\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(rf, \"RandomForest\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98df17",
   "metadata": {},
   "source": [
    "#### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3e15762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] GradientBoosting\n",
      "✅ Accuracy : 0.7658\n",
      "✅ F1-score : 0.7640\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(grbt, \"GradientBoosting\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(grbt, \"GradientBoosting\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bba34e",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7be175e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] XGBoost\n",
      "✅ Accuracy : 0.7961\n",
      "✅ F1-score : 0.7897\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(xgb, \"XGBoost\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(xgb, \"XGBoost\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4e715",
   "metadata": {},
   "source": [
    "#### Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6532b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶️ [TF-IDF] SoftVoting\n",
      "✅ Accuracy : 0.8157\n",
      "✅ F1-score : 0.8124\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "evaluate_model(voting_classifier, \"SoftVoting\", x_train_tfidf, y_train, x_test_tfidf, y_test, vector_type=\"TF-IDF\")\n",
    "\n",
    "# # Word2Vec\n",
    "# evaluate_model(lsvc, \"LinearSVC\", x_w2v_avg_train, y_train, x_w2v_avg_test, y_test, vector_type=\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08e38f",
   "metadata": {},
   "source": [
    "#### 모델별 성능 비교표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3de9c1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>SoftVoting</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7707</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.7658</td>\n",
       "      <td>0.7654</td>\n",
       "      <td>0.8059</td>\n",
       "      <td>0.6999</td>\n",
       "      <td>0.8157</td>\n",
       "      <td>0.7961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.7459</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>0.8124</td>\n",
       "      <td>0.7897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model     ComplementNB  DecisionTree  GradientBoosting  LinearSVC  \\\n",
       "Accuracy        0.7707         0.618            0.7658     0.7654   \n",
       "F1-score        0.7459         0.573            0.7640     0.7614   \n",
       "\n",
       "Model     LogisticRegression  RandomForest  SoftVoting  XGBoost  \n",
       "Accuracy              0.8059        0.6999      0.8157   0.7961  \n",
       "F1-score              0.8000        0.6757      0.8124   0.7897  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_5000_df = pd.DataFrame(results_5000)\n",
    "pivot = results_5000_df.pivot_table(index='Model', values=['Accuracy', 'F1-score']).T\n",
    "display(pivot.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ceaf32",
   "metadata": {},
   "source": [
    "# 2. 딥러닝 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeaadde",
   "metadata": {},
   "source": [
    "## 2.1 Machine Learning\n",
    "위에서 만들어놓은 x_w2v_avg_train(test) 임베딩 데이터 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64df99cc",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f8b6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2382400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy : 0.7222\n",
      "✅ F1-score : 0.7030\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "xgb_model = XGBClassifier(n_estimators=100, max_depth=5, eval_metric='mlogloss')\n",
    "xgb_model.fit(x_w2v_avg_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = xgb_model.predict(x_w2v_avg_test)\n",
    "\n",
    "# 평가 지표\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"✅ Accuracy : {acc:.4f}\")\n",
    "print(f\"✅ F1-score : {f1:.4f}\")\n",
    "\n",
    "# 결과 리스트에 결과 저장\n",
    "results_dl.append({\n",
    "    'Model': 'XGBoost',\n",
    "    'Accuracy': acc,\n",
    "    'F1-score': f1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42f6539",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "edc1737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy : 0.7262\n",
      "✅ F1-score : 0.7246\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "lr_model = LogisticRegression(C=10000, penalty='l2', max_iter=3000, random_state=0)\n",
    "lr_model.fit(x_w2v_avg_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = lr_model.predict(x_w2v_avg_test)\n",
    "\n",
    "# 평가 지표\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"✅ Accuracy : {acc:.4f}\")\n",
    "print(f\"✅ F1-score : {f1:.4f}\")\n",
    "\n",
    "# 결과 리스트에 결과 저장\n",
    "results_dl.append({\n",
    "    'Model': 'LogisticRegression',\n",
    "    'Accuracy': acc,\n",
    "    'F1-score': f1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8069e",
   "metadata": {},
   "source": [
    "## 2.2 DeepLearning\n",
    "위에서 만들어놓은 x_train(test)_w2v 임베딩 데이터 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072d908",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a79b3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6638c1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25600</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,107,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25600\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m13,107,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │         \u001b[38;5;34m5,934\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,179,310</span> (50.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,179,310\u001b[0m (50.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,179,310</span> (50.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,179,310\u001b[0m (50.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 정의\n",
    "dense_model = Sequential([\n",
    "    Flatten(input_shape=(100, 256)),  # (seq_len, embedding_dim)\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "dense_model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# 모델 확인\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a641d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EarlyStopping 콜백 추가\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,  \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e09d84bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.4754 - loss: 2.4535 - val_accuracy: 0.6444 - val_loss: 1.5387\n",
      "Epoch 2/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.6708 - loss: 1.3596 - val_accuracy: 0.6878 - val_loss: 1.3731\n",
      "Epoch 3/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.7435 - loss: 1.0398 - val_accuracy: 0.6956 - val_loss: 1.3538\n",
      "Epoch 4/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.7985 - loss: 0.7722 - val_accuracy: 0.6978 - val_loss: 1.3770\n",
      "Epoch 5/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8432 - loss: 0.6116 - val_accuracy: 0.6962 - val_loss: 1.4252\n",
      "Epoch 6/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8643 - loss: 0.4934 - val_accuracy: 0.6962 - val_loss: 1.5037\n",
      "Epoch 7/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8943 - loss: 0.4174 - val_accuracy: 0.6956 - val_loss: 1.5539\n",
      "Epoch 8/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.8976 - loss: 0.3831 - val_accuracy: 0.6945 - val_loss: 1.6312\n",
      "Epoch 9/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9193 - loss: 0.3239 - val_accuracy: 0.6878 - val_loss: 1.7181\n",
      "Epoch 10/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9128 - loss: 0.3327 - val_accuracy: 0.6861 - val_loss: 1.7262\n",
      "Epoch 11/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9296 - loss: 0.2932 - val_accuracy: 0.6934 - val_loss: 1.7561\n",
      "Epoch 12/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9335 - loss: 0.2777 - val_accuracy: 0.6884 - val_loss: 1.8044\n",
      "Epoch 13/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9310 - loss: 0.3275 - val_accuracy: 0.6917 - val_loss: 1.8478\n",
      "Epoch 14/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9440 - loss: 0.2294 - val_accuracy: 0.6928 - val_loss: 1.8628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x35c3ca620>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 \n",
    "dense_model.fit(x_train_w2v, y_train,\n",
    "                epochs=100,    # epochs 증가\n",
    "                batch_size=256, # batch_size 증가\n",
    "                validation_split=0.2,\n",
    "                callbacks=[early_stop]  # 대신 early stopping 사용\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d958ba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "✅ Accuracy: 0.6817\n",
      "✅ F1-score: 0.6526\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = dense_model.predict(x_test_w2v)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "print(f\"✅ F1-score: {f1:.4f}\")\n",
    "\n",
    "# 결과 리스트에 결과 저장\n",
    "results_dl.append({\n",
    "    'Model': 'Dense',\n",
    "    'Accuracy': acc,\n",
    "    'F1-score': f1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea3b1c",
   "metadata": {},
   "source": [
    "### RNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fab7d256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaeseunghee/miniconda3/envs/tf_aiffel/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,990</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m197,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │         \u001b[38;5;34m2,990\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">208,366</span> (813.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m208,366\u001b[0m (813.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">208,366</span> (813.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m208,366\u001b[0m (813.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rnn 시계열 특징 데이터 특화 모델\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    LSTM(128, input_shape=(100, 256)),  # (seq_len, embedding_dim)\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(46, activation='softmax')   # 클래스 수에 맞게 조정 46개로 맞춰주세요~\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd976132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - accuracy: 0.3264 - loss: 3.4148 - val_accuracy: 0.4669 - val_loss: 2.1127\n",
      "Epoch 2/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.4675 - loss: 2.1438 - val_accuracy: 0.5470 - val_loss: 1.7743\n",
      "Epoch 3/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.5365 - loss: 1.8223 - val_accuracy: 0.6121 - val_loss: 1.6411\n",
      "Epoch 4/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.5988 - loss: 1.6662 - val_accuracy: 0.6455 - val_loss: 1.5135\n",
      "Epoch 5/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.6292 - loss: 1.5642 - val_accuracy: 0.6600 - val_loss: 1.4206\n",
      "Epoch 6/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.6466 - loss: 1.4647 - val_accuracy: 0.6528 - val_loss: 1.3995\n",
      "Epoch 7/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.6462 - loss: 1.4709 - val_accuracy: 0.6611 - val_loss: 1.3912\n",
      "Epoch 8/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.6501 - loss: 1.4575 - val_accuracy: 0.6728 - val_loss: 1.3314\n",
      "Epoch 9/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.6651 - loss: 1.3610 - val_accuracy: 0.6895 - val_loss: 1.2999\n",
      "Epoch 10/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.6848 - loss: 1.3012 - val_accuracy: 0.6934 - val_loss: 1.2525\n",
      "Epoch 11/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.6973 - loss: 1.2491 - val_accuracy: 0.6973 - val_loss: 1.2315\n",
      "Epoch 12/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.6930 - loss: 1.2517 - val_accuracy: 0.7090 - val_loss: 1.1989\n",
      "Epoch 13/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.7158 - loss: 1.1495 - val_accuracy: 0.7084 - val_loss: 1.1939\n",
      "Epoch 14/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.7200 - loss: 1.1539 - val_accuracy: 0.7201 - val_loss: 1.1530\n",
      "Epoch 15/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.7290 - loss: 1.1229 - val_accuracy: 0.7301 - val_loss: 1.1526\n",
      "Epoch 16/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.7427 - loss: 1.0483 - val_accuracy: 0.7329 - val_loss: 1.1333\n",
      "Epoch 17/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.7489 - loss: 1.0364 - val_accuracy: 0.7307 - val_loss: 1.1305\n",
      "Epoch 18/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - accuracy: 0.7499 - loss: 1.0336 - val_accuracy: 0.7407 - val_loss: 1.0934\n",
      "Epoch 19/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.7547 - loss: 1.0075 - val_accuracy: 0.7468 - val_loss: 1.0607\n",
      "Epoch 20/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.7543 - loss: 0.9975 - val_accuracy: 0.7457 - val_loss: 1.0654\n",
      "Epoch 21/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.7625 - loss: 0.9496 - val_accuracy: 0.7546 - val_loss: 1.0613\n",
      "Epoch 22/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.7682 - loss: 0.9320 - val_accuracy: 0.7462 - val_loss: 1.0609\n",
      "Epoch 23/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.7783 - loss: 0.9101 - val_accuracy: 0.7462 - val_loss: 1.0542\n",
      "Epoch 24/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.7821 - loss: 0.8810 - val_accuracy: 0.7540 - val_loss: 1.0221\n",
      "Epoch 25/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.7849 - loss: 0.8863 - val_accuracy: 0.7579 - val_loss: 1.0201\n",
      "Epoch 26/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.7865 - loss: 0.8568 - val_accuracy: 0.7629 - val_loss: 1.0477\n",
      "Epoch 27/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.7888 - loss: 0.8271 - val_accuracy: 0.7579 - val_loss: 1.0504\n",
      "Epoch 28/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.7962 - loss: 0.8280 - val_accuracy: 0.7613 - val_loss: 1.0353\n",
      "Epoch 29/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.7896 - loss: 0.8310 - val_accuracy: 0.7618 - val_loss: 1.0538\n",
      "Epoch 30/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.7982 - loss: 0.8166 - val_accuracy: 0.7679 - val_loss: 1.0596\n",
      "Epoch 31/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.7961 - loss: 0.8154 - val_accuracy: 0.7574 - val_loss: 1.0310\n",
      "Epoch 32/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.8093 - loss: 0.7619 - val_accuracy: 0.7563 - val_loss: 1.0426\n",
      "Epoch 33/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.8139 - loss: 0.7422 - val_accuracy: 0.7607 - val_loss: 1.0267\n",
      "Epoch 34/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.8138 - loss: 0.7449 - val_accuracy: 0.7685 - val_loss: 1.0357\n",
      "Epoch 35/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.8170 - loss: 0.7258 - val_accuracy: 0.7702 - val_loss: 1.0314\n",
      "Epoch 36/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.8317 - loss: 0.6660 - val_accuracy: 0.7518 - val_loss: 1.0295\n",
      "Epoch 37/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.8218 - loss: 0.7046 - val_accuracy: 0.7657 - val_loss: 1.0395\n",
      "Epoch 38/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.8199 - loss: 0.7091 - val_accuracy: 0.7707 - val_loss: 1.0804\n",
      "Epoch 39/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.8209 - loss: 0.7104 - val_accuracy: 0.7657 - val_loss: 1.0291\n",
      "Epoch 40/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.8378 - loss: 0.6506 - val_accuracy: 0.7668 - val_loss: 1.0404\n",
      "Epoch 41/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.8465 - loss: 0.6261 - val_accuracy: 0.7624 - val_loss: 1.0448\n",
      "Epoch 42/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.8456 - loss: 0.5978 - val_accuracy: 0.7730 - val_loss: 1.0538\n",
      "Epoch 43/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.8323 - loss: 0.6412 - val_accuracy: 0.7646 - val_loss: 1.0639\n",
      "Epoch 44/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.8333 - loss: 0.6500 - val_accuracy: 0.7579 - val_loss: 1.0962\n",
      "Epoch 45/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.8303 - loss: 0.6425 - val_accuracy: 0.7629 - val_loss: 1.0545\n",
      "Epoch 46/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.8439 - loss: 0.6193 - val_accuracy: 0.7785 - val_loss: 1.0425\n",
      "Epoch 47/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.8525 - loss: 0.5875 - val_accuracy: 0.7752 - val_loss: 1.0536\n",
      "Epoch 48/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.8594 - loss: 0.5597 - val_accuracy: 0.7807 - val_loss: 1.0643\n",
      "Epoch 49/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.8633 - loss: 0.5362 - val_accuracy: 0.7802 - val_loss: 1.0700\n",
      "Epoch 50/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.8699 - loss: 0.5176 - val_accuracy: 0.7802 - val_loss: 1.0703\n",
      "Epoch 51/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.8719 - loss: 0.5053 - val_accuracy: 0.7841 - val_loss: 1.0707\n",
      "Epoch 52/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.8667 - loss: 0.4990 - val_accuracy: 0.7757 - val_loss: 1.1331\n",
      "Epoch 53/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.8641 - loss: 0.5209 - val_accuracy: 0.7774 - val_loss: 1.0914\n",
      "Epoch 54/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.8773 - loss: 0.4822 - val_accuracy: 0.7707 - val_loss: 1.1003\n",
      "Epoch 55/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.8582 - loss: 0.5449 - val_accuracy: 0.7802 - val_loss: 1.1182\n",
      "Epoch 56/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.8714 - loss: 0.5045 - val_accuracy: 0.7780 - val_loss: 1.1222\n",
      "Epoch 57/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.8789 - loss: 0.4658 - val_accuracy: 0.7735 - val_loss: 1.1202\n",
      "Epoch 58/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.8639 - loss: 0.5268 - val_accuracy: 0.7813 - val_loss: 1.1402\n",
      "Epoch 59/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.8713 - loss: 0.4855 - val_accuracy: 0.7830 - val_loss: 1.1342\n",
      "Epoch 60/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.8746 - loss: 0.4664 - val_accuracy: 0.7629 - val_loss: 1.2310\n",
      "Epoch 61/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - accuracy: 0.8511 - loss: 0.5941 - val_accuracy: 0.7685 - val_loss: 1.0988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x360086c50>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 \n",
    "rnn_model.fit(x_train_w2v, y_train,\n",
    "              epochs=100,    # epochs 증가\n",
    "              batch_size=256, # batch_size 증가\n",
    "              validation_split=0.2,\n",
    "              callbacks=[early_stop]  # 대신 early stopping 사용\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce92b36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "✅ Accuracy: 0.7636\n",
      "✅ F1-score: 0.7476\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = rnn_model.predict(x_test_w2v)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "print(f\"✅ F1-score: {f1:.4f}\")\n",
    "\n",
    "# 결과 리스트에 결과 저장\n",
    "results_dl.append({\n",
    "    'Model': 'RNN',\n",
    "    'Accuracy': acc,\n",
    "    'F1-score': f1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ca772",
   "metadata": {},
   "source": [
    "### CNN + Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "879fd6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaeseunghee/miniconda3/envs/tf_aiffel/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,990</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m163,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │         \u001b[38;5;34m2,990\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">274,030</span> (1.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m274,030\u001b[0m (1.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">274,030</span> (1.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m274,030\u001b[0m (1.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Bidirectional\n",
    "\n",
    "cnn_lstm_model = Sequential([\n",
    "    Conv1D(128, 5, activation='relu', input_shape=(100, 256)),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3f72592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 172ms/step - accuracy: 0.3408 - loss: 2.9797 - val_accuracy: 0.5977 - val_loss: 1.6466\n",
      "Epoch 2/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.5914 - loss: 1.7529 - val_accuracy: 0.6516 - val_loss: 1.4864\n",
      "Epoch 3/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.6355 - loss: 1.5809 - val_accuracy: 0.6873 - val_loss: 1.3909\n",
      "Epoch 4/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.6596 - loss: 1.4906 - val_accuracy: 0.6989 - val_loss: 1.3213\n",
      "Epoch 5/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.6743 - loss: 1.4154 - val_accuracy: 0.7123 - val_loss: 1.2624\n",
      "Epoch 6/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.6860 - loss: 1.3289 - val_accuracy: 0.7162 - val_loss: 1.2310\n",
      "Epoch 7/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.6885 - loss: 1.2990 - val_accuracy: 0.7273 - val_loss: 1.1971\n",
      "Epoch 8/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step - accuracy: 0.7175 - loss: 1.2174 - val_accuracy: 0.7268 - val_loss: 1.1557\n",
      "Epoch 9/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.7128 - loss: 1.2235 - val_accuracy: 0.7373 - val_loss: 1.1166\n",
      "Epoch 10/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.7336 - loss: 1.1529 - val_accuracy: 0.7373 - val_loss: 1.1059\n",
      "Epoch 11/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.7347 - loss: 1.1491 - val_accuracy: 0.7396 - val_loss: 1.0844\n",
      "Epoch 12/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.7354 - loss: 1.1030 - val_accuracy: 0.7390 - val_loss: 1.0834\n",
      "Epoch 13/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step - accuracy: 0.7419 - loss: 1.0839 - val_accuracy: 0.7518 - val_loss: 1.0480\n",
      "Epoch 14/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 206ms/step - accuracy: 0.7520 - loss: 1.0314 - val_accuracy: 0.7551 - val_loss: 1.0444\n",
      "Epoch 15/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step - accuracy: 0.7550 - loss: 1.0280 - val_accuracy: 0.7579 - val_loss: 1.0441\n",
      "Epoch 16/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.7596 - loss: 1.0134 - val_accuracy: 0.7579 - val_loss: 1.0274\n",
      "Epoch 17/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.7696 - loss: 0.9728 - val_accuracy: 0.7635 - val_loss: 1.0275\n",
      "Epoch 18/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.7815 - loss: 0.8956 - val_accuracy: 0.7590 - val_loss: 1.0059\n",
      "Epoch 19/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.7825 - loss: 0.8823 - val_accuracy: 0.7707 - val_loss: 1.0092\n",
      "Epoch 20/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.7864 - loss: 0.8714 - val_accuracy: 0.7679 - val_loss: 1.0062\n",
      "Epoch 21/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.8076 - loss: 0.8006 - val_accuracy: 0.7657 - val_loss: 0.9955\n",
      "Epoch 22/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.8082 - loss: 0.7717 - val_accuracy: 0.7674 - val_loss: 1.0142\n",
      "Epoch 23/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.8102 - loss: 0.7477 - val_accuracy: 0.7752 - val_loss: 1.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.8062 - loss: 0.7540 - val_accuracy: 0.7585 - val_loss: 1.0396\n",
      "Epoch 25/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.8085 - loss: 0.7526 - val_accuracy: 0.7707 - val_loss: 1.0081\n",
      "Epoch 26/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.8196 - loss: 0.7377 - val_accuracy: 0.7679 - val_loss: 1.0288\n",
      "Epoch 27/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.8150 - loss: 0.7296 - val_accuracy: 0.7724 - val_loss: 1.0432\n",
      "Epoch 28/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.8278 - loss: 0.6836 - val_accuracy: 0.7668 - val_loss: 1.0177\n",
      "Epoch 29/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step - accuracy: 0.8204 - loss: 0.7052 - val_accuracy: 0.7735 - val_loss: 1.0555\n",
      "Epoch 30/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.8340 - loss: 0.6551 - val_accuracy: 0.7735 - val_loss: 1.0469\n",
      "Epoch 31/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.8436 - loss: 0.6006 - val_accuracy: 0.7774 - val_loss: 1.0391\n",
      "Epoch 32/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.8605 - loss: 0.5481 - val_accuracy: 0.7780 - val_loss: 1.0331\n",
      "Epoch 33/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.8602 - loss: 0.5507 - val_accuracy: 0.7713 - val_loss: 1.0519\n",
      "Epoch 34/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.8668 - loss: 0.5035 - val_accuracy: 0.7741 - val_loss: 1.0529\n",
      "Epoch 35/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - accuracy: 0.8689 - loss: 0.5269 - val_accuracy: 0.7741 - val_loss: 1.1075\n",
      "Epoch 36/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - accuracy: 0.8623 - loss: 0.5006 - val_accuracy: 0.7602 - val_loss: 1.1410\n",
      "Epoch 37/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.8690 - loss: 0.4925 - val_accuracy: 0.7763 - val_loss: 1.1401\n",
      "Epoch 38/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - accuracy: 0.8695 - loss: 0.5000 - val_accuracy: 0.7741 - val_loss: 1.0970\n",
      "Epoch 39/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.8727 - loss: 0.4742 - val_accuracy: 0.7752 - val_loss: 1.1226\n",
      "Epoch 40/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.8830 - loss: 0.4520 - val_accuracy: 0.7757 - val_loss: 1.1301\n",
      "Epoch 41/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.8807 - loss: 0.4362 - val_accuracy: 0.7629 - val_loss: 1.1495\n",
      "Epoch 42/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.8842 - loss: 0.4285 - val_accuracy: 0.7763 - val_loss: 1.1328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x35f570f10>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 \n",
    "cnn_lstm_model.fit(x_train_w2v, y_train,\n",
    "              epochs=100,    \n",
    "              batch_size=256, \n",
    "              validation_split=0.2,\n",
    "              callbacks=[early_stop]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b7d7f542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n",
      "✅ Accuracy: 0.7667\n",
      "✅ F1-score: 0.7509\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = cnn_lstm_model.predict(x_test_w2v)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "print(f\"✅ F1-score: {f1:.4f}\")\n",
    "\n",
    "# 결과 리스트에 결과 저장\n",
    "results_dl.append({\n",
    "    'Model': 'CNN+BiLSTM',\n",
    "    'Accuracy': acc,\n",
    "    'F1-score': f1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fed089",
   "metadata": {},
   "source": [
    "### 모델 성능 비교표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e16829be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>CNN+BiLSTM</th>\n",
       "      <th>Dense</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RNN</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.6817</td>\n",
       "      <td>0.7262</td>\n",
       "      <td>0.7636</td>\n",
       "      <td>0.7222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.7509</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>0.7246</td>\n",
       "      <td>0.7476</td>\n",
       "      <td>0.7030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model     CNN+BiLSTM   Dense  LogisticRegression     RNN  XGBoost\n",
       "Accuracy      0.7667  0.6817              0.7262  0.7636   0.7222\n",
       "F1-score      0.7509  0.6526              0.7246  0.7476   0.7030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_dl_df = pd.DataFrame(results_dl)\n",
    "pivot_dl = results_dl_df.pivot_table(index=None, columns='Model', values=['Accuracy', 'F1-score']).T\n",
    "display(pivot_dl.T.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d312f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_aiffel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
